{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification and Perceptron\n",
    "\n",
    "This exercise gives you an introduction on perceptron and linear classification (binary classification). \n",
    "\n",
    "**Instructions:**\n",
    "- You will be using Python 3.\n",
    "- Fill in `tut2_perceptron.ipynb`. After coding your function, run the cell right below it to check if your result is correct.\n",
    "\n",
    "**After this assignment you will:**\n",
    "- Be able to understand linear classfication and perceptron.\n",
    "- Be able to build a linear function to linearly seperate samples of two classes (binary classification).\n",
    "- Be able to understand the limitation for linear function on non-linear separable data.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Linear Classification with Perceptron ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Linear Classication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear classification is a linear function \n",
    "\n",
    "$$\\begin{align*} & y = f(x) = {w}^{T}x + b \\end{align*}\\tag{1}$$\n",
    "\n",
    "where $w$ denotes the weight of the input instance, $x$ denotes the input variable, that separates instances of different classes. For now, we will focus on the **binary classification** in which the output $y$ can take on only two discrete values called **classes**, -1 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![linear classification](images/linear-classification.png)\n",
    "Perceptron is an algorithm for learning a binary classifier:\n",
    "\n",
    "$$\\begin{align*} & f(x) = \n",
    "    \\begin{cases}\n",
    "        1   & \\quad \\text{if } {w}^{T}x + b \\geq 0 \\\\\n",
    "        -1  & \\quad \\text{if } {w}^{T}x + b < 0\n",
    "      \\end{cases} \\end{align*}\\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, if we are trying to build a spam classifier for email, then $x(i)$ may be some features of a piece of email, and $y$ may be 1 if it is a piece of spam mail, and -1 otherwise. -1 is also called the negative class, and 1 the positive class, and they are sometimes also denoted by the symbols “-” and “+”.\n",
    "\n",
    "From a gepmetric perspective, $w$ is the slope, which are also called **weights**. $b$ is the interceept of the linear function, also called the **bias**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Linear Separability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training instances are linearly separable if there exists a hyperplane that will separate the two classes.\n",
    "First, we will draw some data points on the graph using `plt.scatter` from matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros( (6,2) )\n",
    "X[:,1] = 1\n",
    "for i in range(6): X[i,0] = i+1\n",
    "X\n",
    "Y = np.zeros( 6 )\n",
    "for i in range(6): Y[i] = 0 if i < 3 else 1\n",
    "(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(X[:3,0], Y[:3])\n",
    "plt.scatter(X[3:,0], Y[3:], marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Linearly Seperable\n",
    "Define s function that can linearly seperate the two different classes of examples. \n",
    "\n",
    "**Exercise**: Build a function that returns a list of x,y for the linear function that can linear seperate the two different classes of examples. There can be multiple anwsers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function():\n",
    "    x = np.zeros( 6 )\n",
    "    y = np.zeros( 6 )\n",
    "    for i in range(6): x[i] = i + 1\n",
    "    y = [1, 0.8, 0.6, 0.4, 0.2, 0]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = linear_function()\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(x, y)\n",
    "plt.scatter(X[:3,0], Y[:3])\n",
    "plt.scatter(X[3:,0], Y[3:], marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Non-linearly Seperable\n",
    "\n",
    "What if we add some noise to the data now? The above linear function can no longer linearly seperated the examples. \n",
    "\n",
    "**Exercise**: Build a. function `linear_function_update()` that returns a list of x,y that can linear seperate the two different classes of examples. There can be multiple anwsers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy data\n",
    "Y[3] = 0.2\n",
    "X[3,0] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(X[:3,0], Y[:3])\n",
    "plt.scatter(X[3:,0], Y[3:], marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = linear_function()\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(x, y)\n",
    "plt.scatter(X[:3,0], Y[:3])\n",
    "plt.scatter(X[3:,0], Y[3:], marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function_update():\n",
    "    \"\"\"\n",
    "    Build a linear function that can linearly seperate the above examples.\n",
    "\n",
    "    Return:\n",
    "    x,y -- list of x, y of the linear function\n",
    "    \"\"\"\n",
    "    x = np.zeros( 6 )\n",
    "    y = np.zeros( 6 )\n",
    "    ### START CODE HERE ### (≈ 2 line of code)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = linear_function_update()\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(x, y)\n",
    "plt.scatter(X[:3,0], Y[:3])\n",
    "plt.scatter(X[3:,0], Y[3:], marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do with cases like these?\n",
    "\n",
    "In real life, we usually have data that are non-linearly seperable by linear function like the perceptron algorithm. In these cases, we could not draw a linear line to seperate the two classes of samples completely. Hence, we may need to use other algorithms such as non-linear functions, which we will discuss in the coming tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear_model(rseed=42, n_samples=30):\n",
    "    radius = 40 * np.random.random(n_samples)\n",
    "    far_pts = radius > 20\n",
    "    radius[far_pts] *= 1.2\n",
    "    radius[~far_pts] *= 1.1\n",
    "\n",
    "    theta = np.random.random(n_samples) * np.pi * 2\n",
    "\n",
    "    data = np.empty((n_samples, 2))\n",
    "    data[:, 0] = radius * np.cos(theta)\n",
    "    data[:, 1] = radius * np.sin(theta)\n",
    "\n",
    "    labels = np.ones(n_samples)\n",
    "    labels[far_pts] = -1\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "x, y = nonlinear_model()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = plt.subplot(1, 1, 1, xticks=[], yticks=[])\n",
    "ax.scatter(x[:10, 0], x[:10, 1])\n",
    "ax.scatter(x[10:, 0], x[10:, 1], marker='o')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- Perceptron is an algorithm for learning a binary classifier. \n",
    "    - If data is linearly seperable, the perceptron algorithm will classify samples into 2 classes, namely positive class (1) and negative class (-1). \n",
    "    - If data is non-linearly seperable, we may need to update the perceptron algorithm or use non-linear functions, which will be covered in future tutorials. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
